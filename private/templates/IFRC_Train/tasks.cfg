##########################################################################
# Add a list of csv files to import into the system
# the list of import files is a comma separated list as follows:
# "prefix","tablename","csv file name","stylesheet"
#
# The csv file is assumed to be in the same directory as this file
# The style sheet is assumed to be in either of the following directories:
#     static/format/s3csv/"prefix"/
#     static/format/s3csv/
#     CSV path
#
# For details on how to import data into the system see the following:
#     zzz_1st_run
#     s3import::S3BulkImporter
##########################################################################
# Assumes that all of IFRC has already been imported
# Users
auth,user,demo/masterUsers.csv,user.xsl
*,import_user,users.csv
# Associate Users with Organisations
hrm,person,users.csv,person.xsl
# -----------------------------------------------------------------------------
# GIS
# Layers
gis,layer_config,gis_layer_wms.csv,layer_wms.xsl
gis,layer_config,gis_layer_wms_finnrc.csv,layer_wms.xsl
# -----------------------------------------------------------------------------
# Organisations
org,organisation,organisation.csv,organisation.xsl
# Offices
org,office,office.csv,office.xsl
# Warehouses
inv,warehouse,warehouse.csv,warehouse.xsl
# -----------------------------------------------------------------------------
# HRM
#hrm,skill,default/DefaultSkillList.csv,skill.xsl
#hrm,competency_rating,default/DefaultSkillCompetency.csv,competency_rating.xsl
hrm,person,staff.csv,person.xsl,"{'Type':'Staff'}"
hrm,person,volunteers.csv,person.xsl,"{'Type':'Volunteer'}"
hrm,training,training.csv,training.xsl
hrm,programme_hours,hrm_programme_hours.csv,programme_hours.xsl
hrm,group_membership,hrm_group_membership.csv,group_membership.xsl
# -----------------------------------------------------------------------------
# Members
member,person,members.csv,person.xsl
# -----------------------------------------------------------------------------
# Project Tool
org,facility,facility.csv,facility.xsl
project,status,default/project_status.csv,status.xsl
# Training Data
project,project,project_project.csv,project.xsl
# Just the 1st record
project,location,project_location.csv,location.xsl
project,organisation,project_organisation.csv,organisation.xsl
# -----------------------------------------------------------------------------
# Assets
asset,asset,asset.csv,asset.xsl
# -----------------------------------------------------------------------------
# Inventory
inv,inv_item,inv_item.csv,inv_item.xsl
# Requests
req,req,test/inv-mngt/req_req.csv,req.xsl
req,req_item,test/inv-mngt/req_item.csv,req_item.xsl
# The order in which the items are shipped is important
# so do not try to change the order or merge the following track_item files
inv,track_item,test/inv-mngt/track_item1.csv,track_item.xsl
inv,track_item,test/inv-mngt/track_item2.csv,track_item.xsl
inv,track_item,test/inv-mngt/track_item3.csv,track_item.xsl
# -----------------------------------------------------------------------------
# Events
irs,ireport,ireport.csv,ireport.xsl
# -----------------------------------------------------------------------------
# ADAT
# Add the completed responses to the various templates
# These take a long time to import so only import those we really need
#survey,complete,ADAT/Padang Earthquake 2011 (72H B).csv,complete.xsl
#survey,complete,ADAT/Padang Earthquake 2011 (PMI).csv,complete.xsl
# These fail & gives a consequent transaction error on PostgreSQL
#survey,complete,ADAT/Padang Earthquake 2011 (24H B).csv,complete.xsl
#survey,complete,ADAT/Tropical Storm Bulegila 2012(24H B)-Data.csv,complete.xsl
# Just the 1st record
survey,complete,24H-TL-Data.csv,complete.xsl
# -----------------------------------------------------------------------------
# Vulnerability
# Add sample locations, the indicators and data
vulnerability,aggregated_indicator,Vulnerability/aggregated_indicator.csv,aggregated_indicator.xsl
vulnerability,indicator,Vulnerability/indicator.csv,indicator.xsl
# The vulnerability data comes in three flavours:
# * fast: which is a very small subset enabling to see the system without impacting on prepop times
# * short: sufficient data to properly test the system, grab your coffee (5 minutes)
# * long: lots of data, have lunch (40 minutes)
# In addition there is a historical data set used for the analysis
vulnerability,data,Vulnerability/vulnerability_data_fast.csv,data.xsl
vulnerability,data,Vulnerability/vulnerability_data_short.csv,data.xsl
vulnerability,data,Vulnerability/vulnerability_data_historical_short.csv,data.xsl
#vulnerability,data,Vulnerability/vulnerability_data_long.csv,data.xsl
#vulnerability,data,Vulnerability/vulnerability_data_historical_long.csv,data.xsl
# Demographics (needs to be after Vulnerability)
# Demographic flavours mirror the vulnerability ones
stats,demographic_data,Vulnerability/demographic_data_fast.csv,demographic_data.xsl
stats,demographic_data,Vulnerability/demographic_data_short.csv,demographic_data.xsl
#stats,demographic_data,Vulnerability/demographic_data_long.csv,demographic_data.xsl
# -----------------------------------------------------------------------------
# Campaigns (for TERA integration)
gis,marker,gis_marker.csv,marker.xsl
gis,layer_config,gis_layer_feature.csv,layer_feature.xsl
gis,layer_symbology,gis_layer_feature.csv,layer_feature.xsl
msg,basestation,basestation.csv,basestation.xsl
project,campaign_response_summary,campaign_response_summary.csv,campaign_response_summary.xsl
# END -------------------------------------------------------------------------
